# 05.L1第三关-浦语提示词工程实践

## 1.LangGPT结构化提示词编写实践

背景问题：近期相关研究发现，LLM在对比浮点数字时表现不佳，经验证，internlm2-chat-1.8b (internlm2-chat-7b)也存在这一问题，例如认为13.8<13.11。

任务要求：利用LangGPT优化提示词，使LLM输出正确结果。完成一次并提交截图即可

## 快速部署1.8B模型

环境初始化可以查看文档[LangGPT部署](https://github.com/InternLM/Tutorial/tree/camp3/docs/L1/Prompt)

```bash
CUDA_VISIBLE_DEVICES=0 lmdeploy serve api_server /share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b --server-port 23333 --api-keys internlm2
```
启动成功之后，冒烟验证
```python
from openai  import OpenAI

client = OpenAI(api_key="internlm2", base_url="http://0.0.0.0:23333/v1")

response = client.chat.completions.create(
    model=client.models.list().data[0].id,
    messages=[{"role": "system", "content": "请介绍一下你自己"}],
)

print(response.choices[0].message.content)
```

## 启动图形化

启动图形化窗口，方便调试。
```bash
git clone https://github.com/InternLM/Tutorial.git
cd Tutorial/tools
python -m streamlit run chat_ui.py
```
** 注意：启动完成之后，开启端口映射，浏览器打开，点击保存【保存设置】，可以测试是否能正确推理。如果直接点击【开启新对话】会报错，如果不改代码，就先点击保存设置**

> Example:

输入：数字13.8和13.11 比较大小，那个大

输出： 根据你所说的比较大小，13.8大于13.11。

接下来通过提示工程优化，返回正确结果。

## 提示词工程

提示词的背景介绍：

Prompt是一种用于指导以大语言模型为代表的生成式人工智能生成内容(文本、图像、视频等)的输入方式。它通常是一个简短的文本或问题，用于描述任务和要求。

Prompt可以包含一些特定的关键词或短语，用于引导模型生成符合特定主题或风格的内容。例如，如果我们要生成一篇关于“人工智能”的文章，我们可以使用“人工智能”作为Prompt，让模型生成一篇关于人工智能的介绍、应用、发展等方面的文章。

Prompt还可以包含一些特定的指令或要求，用于控制生成文本的语气、风格、长度等方面。例如，我们可以使用“请用幽默的语气描述人工智能的发展历程”作为Prompt，让模型生成一篇幽默风趣的文章。

总之，Prompt是一种灵活、多样化的输入方式，可以用于指导大语言模型生成各种类型的内容。


<br><br>
<Vssue :title="$title" />
